{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for a kaggle competition: https://www.kaggle.com/c/bosch-production-line-performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import pandas\n",
    "import time\n",
    "import io\n",
    "import zipfile\n",
    "import numpy\n",
    "print('imports complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FYI: This takes about a minute and a half\n",
    "def load_and_unzip(filename):\n",
    "    print('loading and unzipping large training data file %s' % (filename))\n",
    "    t0 = time.time()\n",
    "    df = pandas.read_csv(filename, compression='zip')\n",
    "    t1 = time.time()\n",
    "    print('completed in %.3f seconds' % (t1-t0))\n",
    "    return df\n",
    "\n",
    "#train_numeric_filename = '../resources/train_numeric.csv.zip'\n",
    "#df_explore = load_and_unzip(train_numeric_filename)\n",
    "#test_numeric_filename = '../resources/test_numeric.csv.zip'\n",
    "#df_test = load_and_unzip(test_numeric_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the empty data with 0. get the mean and std of the entire training dataset, minus the id colum and the dependent variable column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_explore = pandas.read_csv('../resources/split_train_numeric_a.csv')\n",
    "df_explore.fillna(0,inplace=True)\n",
    "df_explore_meta = df_explore[df_explore.keys()[1:-1]].describe()\n",
    "df_explore_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_training_DMatrix(filename):\n",
    "    arr = numpy.genfromtxt(filename, delimiter=',', skip_header=True, filling_values=0)\n",
    "    return xgboost.DMatrix(arr[:,1:-1], label=arr[:,-1])\n",
    "# load the testing file, without labels\n",
    "def load_testing_DMatrix(filename):\n",
    "    arr = numpy.genfromtxt(filename, delimiter=',', skip_header=True, filling_values=0)\n",
    "    return arr[:,0], xgboost.DMatrix(arr[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = load_training_DMatrix('../resources/train_numeric.csv')\n",
    "param = {'max_depth':2, 'eta':1, 'slient':1, 'objective':'binary:logistic'}\n",
    "num_round = 10\n",
    "bst = xgboost.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids, dtest = load_testing_DMatrix('../resources/test_numeric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('default_xgboost_results.txt', 'w') as f:\n",
    "    f.write('Id,Response\\n')\n",
    "    for i, p in enumerate(pred):\n",
    "        f.write('%d,%s\\n'%(ids[i],'1' if p > 0.5 else '0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the xgboost classifier\n",
    "cross validation with k fold\n",
    "grid search over a few parameters\n",
    "data stored in pandas DataFrame\n",
    "still only using just the numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn.grid_search\n",
    "import sklearn.cross_validation\n",
    "import xgboost.sklearn\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv('../resources/train_numeric.csv')\n",
    "data.fillna(0,inplace=True)\n",
    "target_name = 'Response'\n",
    "target = data[target_name]\n",
    "features = data.drop(target_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] max_depth=6, reg_lambda=1 .......................................\n",
      "[CV] .............................. max_depth=6, reg_lambda=1 - 4.5min\n",
      "[CV] max_depth=6, reg_lambda=1 .......................................\n",
      "[CV] .............................. max_depth=6, reg_lambda=1 - 4.4min\n",
      "[CV] max_depth=6, reg_lambda=1 .......................................\n",
      "[CV] .............................. max_depth=6, reg_lambda=1 - 4.4min\n",
      "[CV] max_depth=6, reg_lambda=1 .......................................\n",
      "[CV] .............................. max_depth=6, reg_lambda=1 - 4.4min\n",
      "[CV] max_depth=6, reg_lambda=1 .......................................\n",
      "[CV] .............................. max_depth=6, reg_lambda=1 - 4.4min\n",
      "[CV] max_depth=6, reg_lambda=1 .......................................\n",
      "[CV] .............................. max_depth=6, reg_lambda=1 - 4.4min\n",
      "[CV] max_depth=6, reg_lambda=1 .......................................\n",
      "[CV] .............................. max_depth=6, reg_lambda=1 - 4.4min\n",
      "[CV] max_depth=6, reg_lambda=1 .......................................\n",
      "[CV] .............................. max_depth=6, reg_lambda=1 - 4.4min\n",
      "[CV] max_depth=6, reg_lambda=1 .......................................\n",
      "[CV] .............................. max_depth=6, reg_lambda=1 - 4.4min\n",
      "[CV] max_depth=6, reg_lambda=1 .......................................\n",
      "[CV] .............................. max_depth=6, reg_lambda=1 - 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 44.4min finished\n"
     ]
    }
   ],
   "source": [
    "def perf_metric(y_true, y_predict):\n",
    "    return sklearn.metrics.matthews_corrcoef(y_true, y_predict)\n",
    "\n",
    "def fit_model(X,y):\n",
    "    cv_sets = sklearn.cross_validation.ShuffleSplit(X.shape[0], n_iter=10, test_size=0.1, random_state=0)\n",
    "    clf = xgboost.sklearn.XGBClassifier(nthread=14)\n",
    "    params = {\n",
    "                'max_depth' : [6],\n",
    "                'reg_lambda' : [1]\n",
    "             }\n",
    "    scoring_fnc = sklearn.metrics.make_scorer(perf_metric)\n",
    "    grid = sklearn.grid_search.GridSearchCV(clf, params, scoring=scoring_fnc, cv=cv_sets, verbose=2)\n",
    "    grid = grid.fit(X,y)\n",
    "    return grid.best_estimator_\n",
    "\n",
    "clf = fit_model(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 100,\n",
       " 'nthread': 14,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pandas.read_csv('../resources/test_numeric.csv')\n",
    "pred = clf.predict(test_data)\n",
    "with open('xgboost_all_numeric_results.txt', 'w') as f:\n",
    "    f.write('Id,Response\\n')\n",
    "    for i, p in enumerate(pred):\n",
    "        f.write('%d,%d\\n'%(test_data['Id'][i],p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
